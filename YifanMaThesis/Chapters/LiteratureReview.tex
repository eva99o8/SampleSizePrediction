\externaldocument{Introduction,LiteratureReview, Methods, Example, Discussion, Conclusion}


\chapter{Literature Review}

Multiple regression analysis is a commonly used method of predictive modeling, which involves using several predictor variables to make predictions about a dependent variable. However, when the predictor variables are stochastic or random, the accuracy of the predictions can be compromised. This chapter reviews three seminal studies that investigate the impact of stochastic predictor variables on the accuracy of predictions made using multiple regression equations.

\cite{kerridge1967errors}focuses on examining the predictive errors of multiple regression equations when the predictor variables are treated as random variables drawn from a multivariate normal population. The conventional treatment of multiple regression assumes independent variables as constants, but in many practical applications, it is more reasonable to consider them as random variables. The paper suggests that despite the limitations of using regression or stochastic predictor variables, it can still be useful if the limitations are well-understood, particularly when dealing with a large number of predictor variables. Kerridge investigates the prediction error that can occur when using multiple regression with stochastic predictor variables. Kerridge shows that the prediction error can be approximated distributionally by the product of a standard normal variable and the square root of an independent Beta-variate. The mean square can be approximated by 
\begin{equation}\label{eq:kerridge}
PMSE = \sigma^2\left(1+\frac{1}{n}\right)\left(\frac{n-2}{n-k-2}\right),
\end{equation}
where $\sigma^2$ is the variance of the error term in the regression, $n$ is the sample size, $k$ is the number of predictors. The paper provided a widely used approximation of $PMSE$.

\cite{narula1974predictive} discusses the problem of variable selection in regression analysis. Although this topic has been thoroughly researched in the literature, most previous studies have focused on selecting subsets of predictor variables that are treated as fixed. Narula proposes a decision rule for selecting a subset of predictor variables that are stochastic, which leads to a smaller prediction mean squared error (PMSE) compared to the conventional approach. Specifically, Narula shows that the PMSE can be decomposed into the variance of the regression coefficients and the variance of the random errors in the case of stochastic predictor variables. By quantifying these two sources of variance, Narula provides a method for assessing the accuracy of predictions made using stochastic predictor variables. The article presents a proof for the derived subset PMSE formula: 
\begin{equation}\label{eq:narula}
PMSE_{subset} = \sigma_p^2\left(1+\frac{1}{n}\right)\left(\frac{n-2}{n-k-2}\right),\end{equation} 
where $\sigma_p^2$ represents the error term for the subset regression, $p$ is the number of predictors in the subset. The proof is provided in the Appendix, as \cite{narula1974predictive} only presents the conclusion without the supporting details. Overall, Narula's approach is a valuable contribution to variable selection in regression analysis, especially when working with stochastic predictor variables, as it leads to more accurate predictions.

\cite{sawyer1982sample} focuses on cases where one is interested in specifying prediction accuracy before collecting sample data, predictors are not subject to experimental control, and one is interested in specifying prediction accuracy averaged with respect to the distribution of the predictors.\cite{sawyer1982sample} explores the accurate approximate distribution of mean absolute error ($MAE$) as a combination of normal distribution and derivative of the normal distribution as
\begin{equation}\label{eq:sawyer}
Prob(\hat{y} - y \leq t) = \Phi\left(\frac{t}{\sigma'}\right) + \frac{p}{4(n-2)(n-p-4)}\Phi^{(4)}\left(\frac{t}{\sigma'}\right),\end{equation}
where $\hat{y}$ is the prediction of response, $y$ is the corresponding true value of response,$\Phi$ is the standard normal distribution function, $\Phi^{(4)}$ is its fourth derivative, $\sigma' = \sqrt{MSE}$, 
. The approximation has been significantly proven to be better than a simple normal approximation. In the discussion section, Sawyer argues that as the number of predictor variables increases, the sample size required to achieve a given level of accuracy also increases.  The approximate inflation in MAE due to the regression coefficients is a simple function of the base sample size and the number of predictors. The advantage of using MAE is that it has a simple definition, making it easily understandable to people who use prediction equations but have little statistical training. 

The three seminal studies investigate the impact of stochastic predictor variables on the accuracy of predictions made using multiple regression equations. These studies propose different approaches for handling stochastic predictor variables in regression analysis, including approximations for prediction, mean squared error, and mean absolute error. These approaches are useful for improving the accuracy of predictions in practical applications, particularly when dealing with a large number of predictor variables. Additionally, the studies provide valuable insights into variable selection in regression analysis and predicting accuracy before collecting sample data. 